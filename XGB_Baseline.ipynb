{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7978ba83-45d6-4d57-bbee-b0ea8bcb6b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor as xgbr\n",
    "from xgboost import XGBClassifier as xgbc\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, f1_score, roc_auc_score, log_loss\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821bf436-7d2d-4b92-ae53-4471cf35fc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94606, 548)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/epcg23.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5052b9e-e3b3-4669-9770-09a73ecf243a",
   "metadata": {},
   "source": [
    "---\n",
    "## Y label: \n",
    "**Probability of recent bachelor graduates getting a paid job within there field after graduation.**\n",
    "1) **WRKG** Working for pay or profit during reference week\n",
    "2) **OCEDRLP** Extent that principal job is related to highest degree\n",
    "3) **DGRDG** Highest degree type\n",
    "4) **STRTYR** Year principal job started\n",
    "5) **DGRYR** Year of award of highest degree\n",
    "\n",
    "```\n",
    "* If 1, 2 and 3 is check out, and year of 4 is => year of 5 then Y=1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27e70d-6bea-458a-bfe4-7fcfec3149bc",
   "metadata": {},
   "source": [
    "### Other relevant features  \n",
    "* **LFSTAT** Labor force status\n",
    "* **DGRDG** Highest degree type\n",
    "* **HDMN** Month of award of highest degree\n",
    "* **NDGMEMG** Field of study for highest degree (major group)\n",
    "* **NDGMENG** Field of study for highest degree (minor group)\n",
    "* **HDPBP21C** Public/private status of school awarding highest degree - 2021 Carnegie code\n",
    "* **HDRGN** Location of school awarding highest degree (region code)\n",
    "* **BAYR** Year of award of first bachelors degree\n",
    "* **CLICWKR** Certificates and licenses: for work-related reasons\n",
    "* **CLICNOW** Certification or licenses: for principal job\n",
    "* **CLICISS** Certification or licenses: issuer\n",
    "* **CLICCODE** Certification/license primary subject or field of study\n",
    "* **CLICYR** Certification or licenses: year first issued\n",
    "### **Demograhic Related**\n",
    "* **AGE** Age\n",
    "* **SEX_2023** Sex at birth\n",
    "* **CTZN** Citizenship or visa status\n",
    "* **CTZFOR** Visa type for non-US citizens\n",
    "* **FNUSYR6** The year first came to U.S. for 6 months or longer\n",
    "* **VETSTAT** Veteran status: served on active duty in the US Armed Forces, Reserves, or National Guard\n",
    "### **Geogrophy Related**\n",
    "* **RESPLOC** Respondent location\n",
    "* **RESPLO3_TOGA** 3-Digit Respondent Location (state/country code)\n",
    "* **RESPLCUS** Respondent location (U.S./Non-U.S.)\n",
    "* **EMRG** Region code for employer\n",
    "* **EMST_TOGA** State/country code for employer\n",
    "### **Finacial Related**\n",
    "* **UGLOANR** Amount borrowed to finance UNDERGRADUATE degree(s)\n",
    "* **UGOWER** Amount still owed from financing of UNDERGRADUATE degree(s)\n",
    "* **GRFLN** Financial support for graduate degree(s): Loans from school, banks, and government\n",
    "* **SALARY** Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87f5cc-1912-411d-85d8-047df98bf044",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f09a44-7b9f-461b-abdb-0d91f14b040d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DGRDG       int64\n",
       "WRKG       object\n",
       "SALARY      int64\n",
       "OCEDRLP    object\n",
       "DGRYR       int64\n",
       "STRTYR      int64\n",
       "STRTMN      int64\n",
       "HDMN        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_variables = ['DGRDG','WRKG','SALARY','OCEDRLP','DGRYR','STRTYR','STRTMN','HDMN']\n",
    "df[y_variables].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4769b9cc-fbaf-4b64-8253-736f7b47fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make y label\n",
    "\n",
    "# DGRDG == 1; highest degree is bachelor\n",
    "# WRKG == 'Y'; working \n",
    "# SALARY >= 1; and getting paid i.e. no internship\n",
    "# OCEDRLP in {1,2}; works in field\n",
    "# (DGRYR - STRTYR) < 1; job started within a year after graduation\n",
    "\n",
    "months = (df['STRTYR'] - df['DGRYR']) * 12 + (df['STRTMN'] - df['HDMN'])\n",
    "\n",
    "df['y'] = (\n",
    "    (df['DGRDG'] == 1) &\n",
    "    (df['WRKG'] == 'Y') &\n",
    "    (df['SALARY'] >= 1) & (df['SALARY'] < 9999998) &\n",
    "    (pd.to_numeric(df['OCEDRLP'], errors='coerce').isin([1, 2])) &\n",
    "    (months.between(0, 12, inclusive='both'))\n",
    ").astype(np.float32)  # better for this model\n",
    "\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "# select only those with recent bachelors drop the rest\n",
    "keep = (df['DGRDG'] == 1) & (df['DGRYR'] >= 2021)\n",
    "df = df.loc[keep].copy()\n",
    "\n",
    "# drop the cols used to make y\n",
    "df = df.drop(y_variables, axis=1).copy()\n",
    "\n",
    "# float32 mapping of objs, drop everything else that cant convert\n",
    "yn_map = {'Y': 1, 'N': 0, 'y': 1, 'n': 0}\n",
    "cols_to_drop = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        s = df[col].replace(yn_map)\n",
    "        converted = pd.to_numeric(s, errors='coerce') # object to NaN if failed\n",
    "        # drop only if column is all NaN\n",
    "        if converted.notna().sum() == 0:\n",
    "            cols_to_drop.append(col)\n",
    "        else:\n",
    "            df[col] = converted\n",
    "\n",
    "if cols_to_drop:\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# cast the rest\n",
    "num_cols = df.select_dtypes(include=['number']).columns\n",
    "df[num_cols] = df[num_cols].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081b448c-fe41-41a4-9a88-98fb76f296db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(972, 488)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0af2b1-c7a3-4fb9-9207-1fb7319a6ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All float32: True\n"
     ]
    }
   ],
   "source": [
    "# check to see of all cols are float32\n",
    "float32 = all(df.dtypes == 'float32')\n",
    "print(\"All float32:\", float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa2ce1-29bc-47e8-913d-b78400c26659",
   "metadata": {},
   "source": [
    "---\n",
    "## Gradient Boosted Forest: Classification w/probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2a833ab-f90f-436d-8d63-7d45a8e92108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------Model Performance Metrics------------------------------ \n",
      "Log Loss: 0.45347975365227755 \n",
      "AUC: 0.8430507745266782 \n",
      "F1 Score: 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "X, y = df.drop(columns=['y']), df['y']\n",
    "\n",
    "# train test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "# tuning parameters\n",
    "params = {\n",
    "    'n_estimators': [120, 280, 487],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3],\n",
    "    # 'gamma': [], # loss needed to partition further \n",
    "    'learning_rate': [0.01, 0.05],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8], # fraction of cols to use on trees\n",
    "    'lambda':[1], # regulate w on the conservitive side\n",
    "    'alpha':[0,0.05] # same as lambda.. but diffrent\n",
    "}\n",
    "\n",
    "clas_model = xgbc(\n",
    "    objective='binary:logistic', \n",
    "    n_jobs=1, # to make sure cores are used by sklearn\n",
    "    tree_method='hist',\n",
    "    eval_metric='logloss' # train accorting to log loss metric\n",
    ")\n",
    "\n",
    "clas_grid_search = GridSearchCV(\n",
    "    estimator=clas_model,\n",
    "    param_grid=params,\n",
    "    cv=5,\n",
    "    scoring='neg_log_loss',\n",
    "    n_jobs=11,\n",
    "    # verbose=2\n",
    ")\n",
    "\n",
    "# fit model\n",
    "clas_grid_search.fit(X_train, y_train)\n",
    "clas_best = clas_grid_search.best_estimator_\n",
    "\n",
    "# evaluate the best model\n",
    "probs = clas_best.predict_proba(X_test)[:, 1] # turns out this can do both!!\n",
    "preds = clas_best.predict(X_test) # regular 0/1 labels\n",
    "\n",
    "ll  = log_loss(y_test, probs)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "f1  = f1_score(y_test, preds)\n",
    "\n",
    "print(\n",
    "    '-'*30+'Model Performance Metrics'+'-'*30,\n",
    "    f'\\nLog Loss: {ll}',\n",
    "    f'\\nAUC: {auc}',\n",
    "    f'\\nF1 Score: {f1}',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44d6484f-34cf-46a5-9df0-5f00a08e9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile = \"runs.vim\"\n",
    "with open(logfile, \"a\") as f:\n",
    "    f.write('-'*18 + 'Model Performance Metrics' + '-'*18 + \"\\n\")\n",
    "    f.write(f\"Timestamp: {datetime.now().isoformat(timespec='seconds')}\\n\")\n",
    "    f.write(f\"Log Loss: {ll}\\n\")\n",
    "    f.write(f\"AUC: {auc}\\n\")\n",
    "    f.write(f\"F1 Score: {f1}\\n\")\n",
    "    f.write(\"Best Params:\\n\")\n",
    "    for k, v in clas_grid_search.best_params_.items():\n",
    "        f.write(f\"  {k}: {v}\\n\")\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e409870-b8d6-4e05-840f-00f73fc196b0",
   "metadata": {},
   "source": [
    "---\n",
    "## Resources:\n",
    "* Perameters: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "* Example: xgboosting.com/how-to-use-xgboost-xgbregressor/\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (JVE)",
   "language": "python",
   "name": "jve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
