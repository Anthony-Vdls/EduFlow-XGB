{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7978ba83-45d6-4d57-bbee-b0ea8bcb6b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor as xgbr\n",
    "from xgboost import XGBClassifier as xgbc\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, f1_score, roc_auc_score, log_loss\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(67)\n",
    "random.seed(67)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "821bf436-7d2d-4b92-ae53-4471cf35fc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94606, 548)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/epcg23.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5052b9e-e3b3-4669-9770-09a73ecf243a",
   "metadata": {},
   "source": [
    "---\n",
    "## Y label: \n",
    "**Probability of recent bachelor graduates getting a paid job within there field after graduation.**\n",
    "1) **WRKG** Working for pay or profit during reference week\n",
    "2) **OCEDRLP** Extent that principal job is related to highest degree\n",
    "3) **DGRDG** Highest degree type\n",
    "4) **STRTYR** Year principal job started\n",
    "5) **DGRYR** Year of award of highest degree\n",
    "\n",
    "```\n",
    "* If 1, 2 and 3 is check out, and year of 4 is => year of 5 then Y=1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27e70d-6bea-458a-bfe4-7fcfec3149bc",
   "metadata": {},
   "source": [
    "### Other relevant features  \n",
    "* **LFSTAT** Labor force status\n",
    "* **DGRDG** Highest degree type\n",
    "* **HDMN** Month of award of highest degree\n",
    "* **NDGMEMG** Field of study for highest degree (major group)\n",
    "* **NDGMENG** Field of study for highest degree (minor group)\n",
    "* **HDPBP21C** Public/private status of school awarding highest degree - 2021 Carnegie code\n",
    "* **HDRGN** Location of school awarding highest degree (region code)\n",
    "* **BAYR** Year of award of first bachelors degree\n",
    "* **CLICWKR** Certificates and licenses: for work-related reasons\n",
    "* **CLICNOW** Certification or licenses: for principal job\n",
    "* **CLICISS** Certification or licenses: issuer\n",
    "* **CLICCODE** Certification/license primary subject or field of study\n",
    "* **CLICYR** Certification or licenses: year first issued\n",
    "### **Demograhic Related**\n",
    "* **AGE** Age\n",
    "* **SEX_2023** Sex at birth\n",
    "* **CTZN** Citizenship or visa status\n",
    "* **CTZFOR** Visa type for non-US citizens\n",
    "* **FNUSYR6** The year first came to U.S. for 6 months or longer\n",
    "* **VETSTAT** Veteran status: served on active duty in the US Armed Forces, Reserves, or National Guard\n",
    "### **Geogrophy Related**\n",
    "* **RESPLOC** Respondent location\n",
    "* **RESPLO3_TOGA** 3-Digit Respondent Location (state/country code)\n",
    "* **RESPLCUS** Respondent location (U.S./Non-U.S.)\n",
    "* **EMRG** Region code for employer\n",
    "* **EMST_TOGA** State/country code for employer\n",
    "### **Finacial Related**\n",
    "* **UGLOANR** Amount borrowed to finance UNDERGRADUATE degree(s)\n",
    "* **UGOWER** Amount still owed from financing of UNDERGRADUATE degree(s)\n",
    "* **GRFLN** Financial support for graduate degree(s): Loans from school, banks, and government\n",
    "* **SALARY** Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87f5cc-1912-411d-85d8-047df98bf044",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f09a44-7b9f-461b-abdb-0d91f14b040d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DGRDG       int64\n",
       "WRKG       object\n",
       "SALARY      int64\n",
       "OCEDRLP    object\n",
       "DGRYR       int64\n",
       "STRTYR      int64\n",
       "STRTMN      int64\n",
       "HDMN        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_variables = ['DGRDG','WRKG','SALARY','OCEDRLP','DGRYR','STRTYR','STRTMN','HDMN']\n",
    "df[y_variables].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4769b9cc-fbaf-4b64-8253-736f7b47fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make y label\n",
    "\n",
    "# DGRDG == 1; highest degree is bachelor\n",
    "# WRKG == 'Y'; working \n",
    "# SALARY >= 1; and getting paid i.e. no internship\n",
    "# OCEDRLP in {1,2}; works in field\n",
    "# (DGRYR - STRTYR) < 1; job started within a year after graduation\n",
    "\n",
    "months = (df['STRTYR'] - df['DGRYR']) * 12 + (df['STRTMN'] - df['HDMN'])\n",
    "\n",
    "df['y'] = (\n",
    "    (df['DGRDG'] == 1) &\n",
    "    (df['WRKG'] == 'Y') &\n",
    "    (df['SALARY'] >= 1) & (df['SALARY'] < 9999998) &\n",
    "    (pd.to_numeric(df['OCEDRLP'], errors='coerce').isin([1, 2])) &\n",
    "    (months.between(0, 12, inclusive='both'))\n",
    ").astype(np.float32)  # better for this model\n",
    "\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "# select only those with recent bachelors drop the rest\n",
    "keep = (df['DGRDG'] == 1) & (df['DGRYR'] >= 2021)\n",
    "df = df.loc[keep].copy()\n",
    "\n",
    "# drop the cols used to make y\n",
    "df = df.drop(y_variables, axis=1).copy()\n",
    "\n",
    "# drop the cols that cause memroy leaks, AI helped spot all of these\n",
    "leak_vars = [\n",
    "    # 1) Direct label vars\n",
    "    \"DGRDG\",\"DGRYR\",\"HDMN\",\"STRTYR\",\"STRTMN\",\"WRKG\",\"SALARY\",\"OCEDRLP\",\n",
    "    \"NRCHG\",\"NRCON\",\"NRFAM\",\"NRLOC\",\"NROCNA\",\"NROT\",\"NRPAY\",\"NRREA\",\"NRSEC\",\n",
    "\n",
    "    # 2) Job status / employment\n",
    "    \"HRSWK\",\"WKSLYR\",\"WKSWK\",\"WKSYR\",\"LFSTAT\",\"LOOKWK\",\"LWMN\",\"LWYR\",\"LWNVR\",\n",
    "    \"NWFAM\",\"NWILL\",\"NWLAY\",\"NWNOND\",\"NWOCNA\",\"NWOT\",\"NWRET\",\"NWRTYR\",\"NWSTU\",\n",
    "    \"PJFAM\",\"PJHAJ\",\"PJHRS\",\"PJNOND\",\"PJOCNA\",\"PJOT\",\"PJRET\",\"PJRETYR\",\"PJSTU\",\n",
    "    \"FTPRET\",\"FTPRTYR\",\"WRKGP\",\"SURV_SE\",\"EDTP\",\n",
    "\n",
    "    # 3) Job satisfaction & benefits\n",
    "    \"JOBSATIS\",\"SATADV\",\"SATBEN\",\"SATCHAL\",\"SATIND\",\"SATLOC\",\"SATRESP\",\"SATSAL\",\"SATSEC\",\"SATSOC\",\n",
    "    \"JOBINS\",\"JOBPENS\",\"JOBPROFT\",\"JOBVAC\",\n",
    "\n",
    "    # 4) Work activities\n",
    "    \"ACTCAP\",\"ACTDED\",\"ACTMGT\",\"ACTRD\",\"ACTRD2\",\"ACTRDT\",\"ACTRES\",\"ACTTCH\",\n",
    "    \"WAACC\",\"WAAPRSH\",\"WABRSH\",\"WACOM\",\"WADEV\",\"WADSN\",\"WAEMRL\",\"WAMGMT\",\"WAOT\",\n",
    "    \"WAPRI\",\"WAPROD\",\"WAPRRD\",\"WAPRSM\",\"WAPRSM2\",\"WAPRSM3\",\"WAQM\",\"WASALE\",\n",
    "    \"WASCSM\",\"WASCSM2\",\"WASCSM3\",\"WASVC\",\"WATEA\",\"WASEC\",\n",
    "\n",
    "    # 5) Employer & occupation\n",
    "    \"N2OCPRBG\",\"N2OCPRMG\",\"N3OCPR\",\"N3OCPRNG\",\"N3OCPRX\",\n",
    "    \"N2OCBLST\",\"N2OCMLST\",\"N3OCLST\",\"N3OCLSTX\",\"N3OCNLST\",\n",
    "    \"INDCODE\",\"EMED\",\"EMTP\",\"EMSECDT\",\"EMSECSM\",\"EMSIZE\",\"EMST_TOGA\",\"EMUS\",\n",
    "    \"EMRG\",\"NEDTP\",\"NEWBUS\",\"PBPR21C\",\"CARN21C\",\"MGRNAT\",\"MGROTH\",\"MGRSOC\",\n",
    "    \"SUPDIR\",\"SUPIND\",\"SUPWK\",\"TELEC\",\"TELEFR\",\"PJWTFT\",\"PRMBR\",\"PROMTGI\",\n",
    "\n",
    "    # 6) Training & courses after degree\n",
    "    \"WKTRNI\",\"WTRCHOC\",\"WTREASN\",\"WTREM\",\"WTRLIC\",\"WTROPPS\",\"WTROT\",\"WTRPERS\",\"WTRSKL\",\n",
    "    \"ACADV\",\"ACCAR\",\"ACCCEP\",\"ACCHG\",\"ACDRG\",\"ACEM\",\"ACFPT\",\"ACGRD\",\"ACINT\",\n",
    "    \"ACLIC\",\"ACOT\",\"ACSIN\",\"ACSKL\",\"NACEDMG\",\"NACEDNG\",\n",
    "\n",
    "    # 7) Survey design / admin\n",
    "    \"OBSNUM\",\"SURID\",\"SRVMODE\",\"WTSURVY\",\"COHORT\",\"REFYR\",\"BIRYR\",\n",
    "    # Optional: also drop TCDGCMP if present\n",
    "    \"TCDGCMP\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[c for c in leak_vars if c in df.columns])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# float32 mapping of objs, drop everything else that cant convert\n",
    "yn_map = {'Y': 1, 'N': 0, 'y': 1, 'n': 0}\n",
    "cols_to_drop = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        s = df[col].replace(yn_map)\n",
    "        converted = pd.to_numeric(s, errors='coerce') # object to NaN if failed\n",
    "        # drop only if column is all NaN\n",
    "        if converted.notna().sum() == 0:\n",
    "            cols_to_drop.append(col)\n",
    "        else:\n",
    "            df[col] = converted\n",
    "\n",
    "if cols_to_drop:\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# cast the rest\n",
    "num_cols = df.select_dtypes(include=['number']).columns\n",
    "df[num_cols] = df[num_cols].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "081b448c-fe41-41a4-9a88-98fb76f296db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(972, 337)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d0af2b1-c7a3-4fb9-9207-1fb7319a6ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All float32: True\n"
     ]
    }
   ],
   "source": [
    "# check to see of all cols are float32\n",
    "float32 = all(df.dtypes == 'float32')\n",
    "print(\"All float32:\", float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa2ce1-29bc-47e8-913d-b78400c26659",
   "metadata": {},
   "source": [
    "---\n",
    "## Gradient Boosted Forest: Classification w/probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a833ab-f90f-436d-8d63-7d45a8e92108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------Model Performance Metrics------------------------------ \n",
      "Log Loss: 0.552834519702029 \n",
      "AUC: 0.7921686746987953 \n",
      "F1 Score: 0.7314285714285714\n"
     ]
    }
   ],
   "source": [
    "X, y = df.drop(columns=['y']), df['y']\n",
    "\n",
    "# train test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    # random_state=67,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "\n",
    "# tuning parameters\n",
    "params = {\n",
    "    'n_estimators': [200, 300, 500],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 5],\n",
    "    # 'gamma': [], # loss needed to partition further \n",
    "    'learning_rate': [0.01, 0.001, 0.05],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.66, 0.8], # fraction of cols to use on trees\n",
    "    'lambda':[0.1, 1, 5], # regulate w on the conservitive side\n",
    "    'alpha':[0, 0.1, 1] # same as lambda.. but diffrent\n",
    "}\n",
    "\n",
    "clas_model = xgbc(\n",
    "    objective='binary:logistic', \n",
    "    n_jobs=1, # to make sure cores are used by sklearn\n",
    "    tree_method='hist',\n",
    "    eval_metric='logloss' # train accorting to log loss metric\n",
    ")\n",
    "\n",
    "clas_grid_search = GridSearchCV(\n",
    "    estimator=clas_model,\n",
    "    param_grid=params,\n",
    "    cv=6,\n",
    "    scoring='neg_log_loss',\n",
    "    n_jobs=11,\n",
    "    # verbose=2\n",
    ")\n",
    "\n",
    "# fit model\n",
    "clas_grid_search.fit(X_train, y_train)\n",
    "clas_best = clas_grid_search.best_estimator_\n",
    "\n",
    "# evaluate the best model\n",
    "probs = clas_best.predict_proba(X_test)[:, 1] # turns out this can do both!!\n",
    "preds = clas_best.predict(X_test) # regular 0/1 labels\n",
    "\n",
    "ll  = log_loss(y_test, probs)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "f1  = f1_score(y_test, preds)\n",
    "\n",
    "print(\n",
    "    '-'*30+'Model Performance Metrics'+'-'*30,\n",
    "    f'\\nLog Loss: {ll}',\n",
    "    f'\\nAUC: {auc}',\n",
    "    f'\\nF1 Score: {f1}',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d08ba-d5f1-4693-8d68-27cad554d47c",
   "metadata": {},
   "source": [
    "---\n",
    "## Write scores and best parameters to a log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44d6484f-34cf-46a5-9df0-5f00a08e9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logfile = \"runs.txt\"\n",
    "with open(logfile, \"a\") as f:\n",
    "    f.write('-'*30 + 'Model Performance Metrics' + '-'*30 + \"\\n\")\n",
    "    f.write(f\"Timestamp: {datetime.now().isoformat(timespec='seconds')}\\n\")\n",
    "    f.write(f\"Log Loss: {ll}\\n\")\n",
    "    f.write(f\"AUC: {auc}\\n\")\n",
    "    f.write(f\"F1 Score: {f1}\\n\")\n",
    "    f.write(\"Best Params:\\n\")\n",
    "    for k, v in clas_grid_search.best_params_.items():\n",
    "        f.write(f\"  {k}: {v}\\n\")\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e09e0-db72-4d73-820e-fcb47d86958f",
   "metadata": {},
   "source": [
    "---\n",
    "## Save best patamerts and features to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c485b00-235b-4bd9-ad7d-639b385f3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "with open(\"best_params.json\", \"w\") as f:\n",
    "    json.dump(clas_grid_search.best_params_, f)\n",
    "\n",
    "# save top features\n",
    "top_k = 30\n",
    "top_features = (\n",
    "    pd.Series(clas_best.feature_importances_, index=X_full.columns)\n",
    "      .sort_values(ascending=False)\n",
    "      .head(top_k)\n",
    "      .index\n",
    "      .tolist()\n",
    ")\n",
    "\n",
    "with open(\"top_features.json\", \"w\") as f:\n",
    "    json.dump(top_features, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccfea4a-c5d3-4ec9-b582-ccc49dca888d",
   "metadata": {},
   "source": [
    "---\n",
    "## Make a new model with only best features and perameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "252e782b-1a92-4693-9822-815a2fa8f014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GOVSUP', 'EARN', 'HDACY3', 'ND2MENG', 'CH6', 'HDGRD', 'MRGRD', 'CCST_TOGA', 'CH1218', 'UGFEM', 'CH25', 'HSYR', 'AGE', 'NBAMEBG', 'CHU2', 'CLICNOW', 'NMRMENG', 'FACSEC', 'FSHHS', 'UGFPLN', 'CLICEM', 'D2PBP21C', 'N2ACED', 'NDGMEMG', 'CCCOLPR', 'CHU2IN', 'N2ACEDX', 'NATIVE', 'CHUN12', 'N2D2MEDX']\n"
     ]
    }
   ],
   "source": [
    "# store clas_best features that resulted in the most loss in log loss on split\n",
    "feat_imp = (\n",
    "    pd.Series(clas_best.feature_importances_, index=X_full.columns)\n",
    "      .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# change to how ever many the model will use\n",
    "top_k = 30\n",
    "top_features = feat_imp.head(top_k).index.tolist()\n",
    "\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7057cea-ab48-452f-a790-1fd51b934a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0, 'colsample_bytree': 0.66, 'lambda': 0.1, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 500, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "X_small = X_full[top_features].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_small, y,\n",
    "    test_size=0.2,\n",
    "    random_state=67, # six seven\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "best_params = clas_grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a281015-e1b3-4054-ad80-cd21a9ebf0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Reduced Model ------------------------------ \n",
      "Log Loss: 0.4867325938664912 \n",
      "AUC: 0.8514186701321204 \n",
      "F1 Score: 0.6709677419354839\n"
     ]
    }
   ],
   "source": [
    "reduced_model = xgbc(\n",
    "    objective='binary:logistic',\n",
    "    n_jobs=1,\n",
    "    tree_method='hist',\n",
    "    eval_metric='logloss',\n",
    "    random_state=67, # six seven\n",
    "    **best_params # unpack\n",
    ")\n",
    "\n",
    "reduced_model.fit(X_train, y_train)\n",
    "\n",
    "probs_small = reduced_model.predict_proba(X_test)[:, 1]\n",
    "preds_small = reduced_model.predict(X_test)\n",
    "\n",
    "print(\n",
    "    \"-\"*30 + \" Reduced Model \" + \"-\"*30,\n",
    "    f\"\\nLog Loss: {log_loss(y_test, probs_small)}\",\n",
    "    f\"\\nAUC: {roc_auc_score(y_test, probs_small)}\",\n",
    "    f\"\\nF1 Score: {f1_score(y_test, preds_small)}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3bfbe3-55b9-474e-8569-ec2368267fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a53df8f-e807-46de-8005-5bac392b9f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (JVE)",
   "language": "python",
   "name": "jve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
